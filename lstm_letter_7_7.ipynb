{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8975c84c",
   "metadata": {},
   "source": [
    "This notebook is to build a tashkeel model for arabic poems, it is based on 14 sequence length (best tell now based on our expirements) \n",
    "it utilized Bidirectional LSTM network for this task.\n",
    "first we clean training data then we separate the letter from diacritics in two list.\n",
    "then we build the sequences and prepare the classes\n",
    "after that train the model\n",
    "at the end you canfind the testing model code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d63bd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Bidirectional\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "from tashkeel_lib import basic_diacritics, diacritics , full_diacritics ,clean_text,clean_bayt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3157f3",
   "metadata": {},
   "source": [
    "Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ba3c96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = open(\"main_6_Bayt.csv\", 'r', encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a25dabb",
   "metadata": {},
   "source": [
    "clean raw data from non punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4b0a540",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = clean_text( raw_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df29909",
   "metadata": {},
   "source": [
    "build dictionary for class to integer conversion and integer to class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8da9c6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "diac_to_int = dict((c, i) for i, c in enumerate(full_diacritics))\n",
    "int_to_diac = dict((i, c) for i, c in enumerate(full_diacritics))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd93249c",
   "metadata": {},
   "source": [
    "Build two lists one for letter and one for diacritics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1308606e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "tashkeel = []\n",
    "\n",
    "prev_char = ' '\n",
    "text.append(prev_char)\n",
    "\n",
    "text_index = 0\n",
    "while text_index < len(raw_text):\n",
    "     cur_char = raw_text[text_index] \n",
    "     if cur_char not in diacritics and  prev_char not in diacritics: # letterv then letter\n",
    "        text.append(cur_char)\n",
    "        tashkeel.append('z')\n",
    "        prev_char= cur_char\n",
    "     elif cur_char not in diacritics and  prev_char in diacritics: # tashkeel then letter\n",
    "        text.append(cur_char)\n",
    "        prev_char= cur_char\n",
    "     elif cur_char == 'ّ' and prev_char in basic_diacritics :  # diacritics before chaddah\n",
    "        print('Data error diacritics before chaddah ' + 'ح' + prev_char)\n",
    "        break\n",
    "     elif cur_char in basic_diacritics and prev_char in basic_diacritics :  # double diacritics\n",
    "        print('Data error double diacritics' + 'ح' + cur_char +'   '+ 'ح' + prev_char)\n",
    "        break\n",
    "     elif cur_char in basic_diacritics :\n",
    "        tashkeel.append(cur_char)\n",
    "        prev_char = cur_char \n",
    "     elif cur_char == 'ّ':  # shaddah\n",
    "        if raw_text[text_index +1 ]  in basic_diacritics:\n",
    "            tashkeel.append(raw_text[text_index ]+ raw_text[text_index +1 ])\n",
    "            prev_char = raw_text[text_index +1 ]\n",
    "            text_index = text_index +1\n",
    "        else:\n",
    "            tashkeel.append(cur_char)\n",
    "            prev_char = cur_char\n",
    "     else:\n",
    "        print('Data error uncovered case')\n",
    "        break\n",
    "     text_index = text_index+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ca838bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10915086"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7f4f77",
   "metadata": {},
   "source": [
    "regenerating original text to test the previous step (separation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9b33fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " وَإِن تُنظِراني اليَومَ أَقضِ لُبانَةً وَتَستَوجِبا مَنّاً عَلَيَّ وَتُحمَدا \n",
      " وَإِن ظَهَرَت مِنهُ قَوارِصُ جَمَّةٌ وَأَفرَعَ فِي لَومي مِراراً وَأَصعَدا \n",
      " وَإِن صَرَّحَت كَحلٌ وَهَبَّت عَرِيَّةٌ مِنَ الريحِ لَمْ تَترُك لِذي المالِ مِرفَدا \n",
      " وَلم يَحمِ فَرجَ الحَيِّ إِلَّا مُحافِظٌ كَريمُ المُ"
     ]
    }
   ],
   "source": [
    "for i in range (200):\n",
    "    print(text[i] + tashkeel[i].replace('z',''), end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134452e7",
   "metadata": {},
   "source": [
    "Dictionary to convert from letter class to int and back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8acb0019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  10915086\n",
      "Total Vocab:  38\n"
     ]
    }
   ],
   "source": [
    "# create mapping of unique chars to integers, and a reverse mapping\n",
    "chars = sorted(list(set(text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "\n",
    "# summarize the loaded data\n",
    "n_chars = len(text)\n",
    "n_vocab = len(chars)\n",
    "print (\"Total Characters: \", n_chars)\n",
    "print (\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "097427c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e67e26",
   "metadata": {},
   "source": [
    "Building sequences of letters and the prediction diacritics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b71dbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  10915071\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "n_chars = len(tashkeel)\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "\tseq_in = text[i:i + seq_length -7 ]+ text[i + seq_length -7: i + seq_length ]\n",
    "\tseq_out = tashkeel[i + seq_length-7 ]\n",
    "\tdataX.append([char_to_int[char] for char in seq_in])\n",
    "\tdataY.append(diac_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print (\"Total Patterns: \", n_patterns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb569a6b",
   "metadata": {},
   "source": [
    "treating madd letters sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36a98b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7248516"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keepX = []\n",
    "keepY = []\n",
    "for i , t in  enumerate (dataY):\n",
    "    if t >= 1:\n",
    "        keepX.append(dataX[i]) \n",
    "        keepY.append(dataY[i])\n",
    "    elif t == 0 and int_to_char[dataX[i][7]] in ['ا', 'آ', 'و', 'ي', 'ى','ل']:\n",
    "        keepX.append(dataX[i]) \n",
    "        keepY.append(0)\n",
    "len(keepY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec9eedb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear memory\n",
    "dataY =[]\n",
    "dataX =[]\n",
    "raw_text = ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22ce95e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "n_patterns = len(keepX )\n",
    "X = numpy.reshape(keepX, (n_patterns, seq_length, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5631c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize\n",
    "X = X / float(n_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af7db4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(keepY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36bf13f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two layers LSTM \n",
    "stopped for future expirements\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e0bbd5",
   "metadata": {},
   "source": [
    "define the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c016ea31",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(256, input_shape=(X.shape[1], X.shape[2]))))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2b4ea2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a94769",
   "metadata": {},
   "source": [
    "Start training then save the resulting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1dc54f8d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "56630/56630 [==============================] - 2792s 49ms/step - loss: 0.7923\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.79234, saving model to weights-improvement-01-0.7923.hdf5\n",
      "Epoch 2/6\n",
      "56630/56630 [==============================] - 2730s 48ms/step - loss: 0.5915\n",
      "\n",
      "Epoch 00002: loss improved from 0.79234 to 0.59147, saving model to weights-improvement-02-0.5915.hdf5\n",
      "Epoch 3/6\n",
      "56630/56630 [==============================] - 2624s 46ms/step - loss: 0.5422\n",
      "\n",
      "Epoch 00003: loss improved from 0.59147 to 0.54225, saving model to weights-improvement-03-0.5422.hdf5\n",
      "Epoch 4/6\n",
      "56630/56630 [==============================] - 2604s 46ms/step - loss: 0.5146\n",
      "\n",
      "Epoch 00004: loss improved from 0.54225 to 0.51458, saving model to weights-improvement-04-0.5146.hdf5\n",
      "Epoch 5/6\n",
      "56630/56630 [==============================] - 2636s 47ms/step - loss: 0.4962\n",
      "\n",
      "Epoch 00005: loss improved from 0.51458 to 0.49618, saving model to weights-improvement-05-0.4962.hdf5\n",
      "Epoch 6/6\n",
      "56630/56630 [==============================] - 2627s 46ms/step - loss: 0.4830\n",
      "\n",
      "Epoch 00006: loss improved from 0.49618 to 0.48296, saving model to weights-improvement-06-0.4830.hdf5\n"
     ]
    }
   ],
   "source": [
    "s =model.fit(X, y, epochs=6, batch_size=128, callbacks=callbacks_list)\n",
    "model.save('tashkeel_22_5__M6__7_7.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdab9d4",
   "metadata": {},
   "source": [
    "Load a pretrained model or skip to use current trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09cf550d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('tashkeel_22_5__M6__7_7.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c60bdd",
   "metadata": {},
   "source": [
    "testing the model: note the input is test file cotains unvocalized poems \"test_bayts.txt\" and the result is wretten to \"test_bayt_results.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cca2229e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = open ('test_bayts.txt', 'r', encoding='utf-8')\n",
    "test_bayts = test_file.read()\n",
    "test_file.close()\n",
    "test_bayts = test_bayts.split('\\n')\n",
    "\n",
    "result_file = open('test_bayt_results.txt', 'w', encoding='utf-8')\n",
    "\n",
    "for bayt in test_bayts:\n",
    "    bayt =  clean_bayt(bayt)\n",
    "    seq = []\n",
    "    for i in range (seq_length -9 ):\n",
    "      seq.append(1)  # space\n",
    "    seq.append(0)    # \\n\n",
    "    seq.append(1)   # space\n",
    "    \n",
    "    for i in range(7) :\n",
    "       seq.append(char_to_int[bayt[i]])\n",
    "    \n",
    "    # reset variables \n",
    "    bayt_len = len(bayt)\n",
    "    curr_pos = 0\n",
    "    bayt_tashkeel =[]\n",
    "    \n",
    "    while curr_pos <= bayt_len -8 :\n",
    "        bayt_tashkeel.append( bayt[curr_pos])\n",
    "        x = numpy.reshape(seq, (1, len(seq), 1))\n",
    "        x = x / float(n_vocab)\n",
    "        prediction = model.predict(x, verbose=0)\n",
    "        index = numpy.argmax(prediction)\n",
    "        if bayt[curr_pos] not in [' ','\\n'] and index !=0:\n",
    "           bayt_tashkeel.append( int_to_diac[index])\n",
    "\n",
    "        seq = seq[1:]\n",
    "        seq.append(char_to_int[bayt[curr_pos +7]])\n",
    "        curr_pos = curr_pos +1\n",
    "    \n",
    "    result_file.write(''.join(bayt_tashkeel).strip() +'\\n')\n",
    "result_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1eeafaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "show last bayt result ( if you cannt wait to open the file :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a16326c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'يَحْكُمُ فِيهِ رَشَدَهُ فَهْوَ غَانِمٌ وَمَنْ لَمْ يَحِكُمُ يَشْرَبُ فَهْوَ غَارِمِ\\n     '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(bayt_tashkeel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
